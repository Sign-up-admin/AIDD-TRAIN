# Gemini 大模型调试日志

## 项目: AIDD-TRAIN

### 场景: 解决深度学习训练过程中的 CUDA 显存溢出及后续错误

本次任务记录了从一个棘手的 `CUDA out of memory` 错误开始，逐步诊断并最终成功运行训练脚本的完整过程。这个过程涉及了多种调试策略，从简单的参数调整到深入数据处理流程和模型输出的分析。

### 步骤 1: 初步诊断 - 显存溢出

- **初始错误**: `torch.OutOfMemoryError: CUDA out of memory`。
- **初步分析**: 这是深度学习中非常常见的错误，通常由过大的批处理大小（Batch Size）导致。
- **首次尝试**: 我检查了 `config.py` 文件，并将 `batch_size` 从 `16` 减小到 `8`。但这并未解决问题，说明显存压力远超预期。

### 步骤 2: 深度诊断 - 模型与数据

- **二次尝试**: 我意识到仅调整批处理大小是不够的。`ViSNet` 是一个复杂的图模型，其自身的计算复杂度也很高。因此，我修改了 `config.py`，引入了模型的超参数（如 `visnet_hidden_channels`, `visnet_num_layers`, `visnet_max_neighbors`），并显著降低了它们的值，以减小模型的体积和计算量。
- **根本原因分析**: 尽管模型参数量大幅减少（从 1.6M 降至 304k），显存溢出问题依然存在。这让我断定，问题的根源不在于**平均**的计算负载，而在于**个别**的极端情况。最可能的原因是数据集中存在少数异常巨大的蛋白质图，当这些图被加载时，会瞬间耗尽显存。
- **解决方案 (数据)**:
    1.  **过滤大数据**: 我修改了 `main.py` 中的 `process_item` 函数，将蛋白质原子数的上限设置为 `20000`。(之前为了解决显存问题曾一度降至 `10000`)
    2.  **强制数据重新处理**: 为了让修改生效，我更新了 `main.py` 中的 `DATA_PROCESSING_VERSION` 字符串。这个版本号机制会强制脚本在检测到处理逻辑变更时，要求用户删除旧的已处理数据文件夹 (`processed_data`)，从而触发数据重新生成。

### 步骤 3: 修复新出现的 Bug

- **新错误**: 在解决了显存问题后，出现了一个新的、更清晰的错误：`AttributeError: 'tuple' object has no attribute 'size'`。
- **错误分析**: 这个错误发生在损失函数计算环节。它明确指出，模型返回的 `output` 是一个元组（Tuple），而不是损失函数所期望的张量（Tensor）。这是因为 `ViSNet` 模型的设计会同时返回最终预测值和一些中间结果。
- **解决方案 (代码)**: 我修改了 `main.py` 中的 `ViSNetPDB` 封装模型。在其 `forward` 方法中，我增加了一个判断逻辑：如果 `visnet` 的输出是元组，就只提取并返回其第一个元素（即我们需要的预测值），否则直接返回输出。这样就确保了损失函数总能接收到正确的数据类型。

### 总结与经验

1.  **调试由表及里**: 从最常见的原因（批处理大小）入手，逐步深入到更复杂的原因（模型参数、数据分布）。
2.  **关注极端情况**: 当常规优化手段失效时，应考虑数据集中是否存在导致问题的“离群点”或异常样本。
3.  **理解代码机制**: 注意代码中可能存在的安全或缓存机制（如本项目中的 `DATA_PROCESSING_VERSION`），这些机制在修改数据处理流程时必须被考虑到。
4.  **仔细阅读错误信息**: 后续的 `AttributeError` 比起宽泛的“显存溢出”提供了更精确的线索，是定位问题的关键。

# AI Agent 调试日志

## 案例分析: AIDD-TRAIN 项目 CUDA 显存溢出

本次任务展示了 AI Agent 如何通过一系列连贯的推理和工具调用，解决一个复杂的深度学习训练问题。

### 初始问题

用户提供了一个 `CUDA out of memory` 的错误堆栈。这是一个典型的资源限制问题。

### 调试流程

1.  **定位和修改配置**: Agent 首先假设问题源于最常见的原因——批处理大小。
    - **`read_file('main.py')`**: 分析主逻辑，发现 `batch_size` 来自外部配置。
    - **`find_files('config.py')`**: 定位配置文件。
    - **`read_file('config.py')`**: 读取当前配置值 (`'batch_size': 16`)。
    - **`write_file('config.py')`**: 将 `batch_size` 减半，写入新值 `8`。

2.  **深化问题分析**: 当第一次尝试失败后，Agent 推断问题比预想的更复杂。它开始分析模型本身的复杂度。
    - **`read_file('main.py')`**: 检查 `ViSNet` 模型的初始化方式，发现其超参数（如 `hidden_channels`）使用的是代码中的默认值。
    - **`write_file('config.py')`**: 将这些关键的超参数添加到配置文件中，并赋予它们更小的值，旨在直接降低模型的内存占用。

3.  **根本原因推断**: 即使大幅简化了模型，内存溢出问题依然存在。此时，Agent 作出了关键推断：问题根源是**数据异常**，而非模型或批处理大小的普遍设置。数据集中可能存在少数超大样本，导致内存瞬间被耗尽。

4.  **数据级干预与缓存刷新**: Agent 转向修改数据预处理逻辑。
    - **`read_file('main.py')`**: 定位到 `process_item` 函数中用于过滤大分子的代码行。
    - **`write_file('main.py')`**: 调整了原子数上限。最初为了解决内存问题从 `20000` 降至 `10000`，后来又恢复为 `20000`。
    - **识别缓存机制**: Agent 注意到了代码中的 `DATA_PROCESSING_VERSION` 变量，并理解了它的作用——防止使用过时的数据。为了使新的过滤规则生效，Agent 再次修改了 `main.py`，更新了此版本号，这会引导用户删除旧的缓存数据并触发重新处理。

5.  **解决后续错误**: 在解决了核心的内存问题后，出现了一个新的 `AttributeError`。
    - **分析堆栈**: 错误信息清晰地指向模型输出的数据类型与损失函数期望的不匹配（元组 vs 张量）。
    - **精确定位和修复**: Agent 迅速定位到 `ViSNetPDB` 封装类的 `forward` 方法，并添加了一行代码 `if isinstance(output, tuple): return output[0]`，从而优雅地解决了这个问题。

### Agent 能力总结

- **多步推理**: 能够根据失败的尝试不断调整策略，从表面问题深入到根本原因。
- **代码理解**: 准确理解了配置文件、模型初始化、数据处理函数以及版本控制机制在代码中的作用。
- **假设与验证**: 能够提出假设（“是批处理太大”、“是模型太大”、“是数据问题”），并通过修改代码和观察结果来验证或推翻这些假设。
- **精确修复**: 最终的修复方案精准且高效，直接解决了代码逻辑上的小缺陷。

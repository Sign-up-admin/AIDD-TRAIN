'''
# 16GB显卡生产环境调试总结 (AIDD-TRAIN 项目)

## 核心问题
在为16GB显存的GPU配置生产环境参数时，反复遭遇 `torch.OutOfMemoryError` (OOM) 错误，即CUDA显存溢出。

---

## 调试过程与关键发现

我们通过“上下限探索法”，在多次失败的尝试中，逐步逼近硬件的真实极限，最终得出了以下关键结论：

1.  **模型复杂度是硬性上限**：
    我们发现，当模型参数量达到约82万（`hidden_channels=96`, `num_layers=5`）时，即便使用极小的物理批次（`batch_size=4`），程序依然会在第一个批次就崩溃。这证明，对于这块16GB的显卡，模型本身（包括其权重、优化器状态、前向传播的中间变量）的开销已经触及了显存天花板。

2.  **物理批次大小是敏感红线**：
    我们发现，当物理批次大小（`batch_size`）设置为8时，即便使用我们最小的30万参数模型，程序依然会在第一个批次就崩溃。这证明，数据批次本身在显存中的占用是一个巨大的、不可忽视的开销，`batch_size=8` 这条红线绝对不能碰。

3.  **“数据彩票”现象是最终杀手**：
    在调试过程中，我们曾找到一个看似完美的配置（30万参数模型 + `batch_size=4`），它成功地稳定运行了4个半小时，处理了145个批次。但在第146个批次，依然因为一个结构异常复杂的“巨无霸”分子而崩溃。这证明，任何处于显存极限边缘的配置，在生产环境中都是不可靠的，因为我们无法预测何时会“中奖”抽到一个极端数据点。

4.  **检查点目录是“罪魁祸首”**：
    在调试初期，我们发现无论如何修改`config.py`，程序依然加载旧的、错误的配置。最终查明，`main.py`的`load_checkpoint`逻辑会加载失败时保存的检查点，从而恢复了导致失败的旧参数。**因此，每次修改配置并重新开始训练前，手动删除旧的、失败的检查点目录，是必须执行的关键一步。**

---

## 参数演进全记录

| 尝试 | 模型参数 (约) | Batch Size | Grad Accum Steps | 结果 | 结论 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| 1 | 2.1M | 16 | 4 | 立刻OOM | 配置过于激进，模型和批次都太大。 |
| 2 | 821k | 8 | 8 | 立刻OOM | 模型依然过大，批次也过大。 |
| 3 | 304k | 4 | 16 | **成功运行 (28批)** | **找到稳定基线！** 但GPU利用率低。 |
| 4 | 821k | 4 | 16 | 立刻OOM | 证明82万参数模型是硬性上限。 |
| 5 | 500k | 4 | 16 | 21批后OOM | 证明配置处于极限边缘，会被“数据彩票”击败。 |
| 6 | 304k | 8 | 8 | 立刻OOM | 证明`batch_size=8`是绝对红线。 |
| 7 | 304k | 4 | 16 | 146批后OOM | 再次验证“数据彩票”理论，此路不通。 |
| 8 | 304k | 2 | 32 | **成功运行** | **找到“防弹模式”**，但GPU利用率更低。 |
| 9 | 500k | 2 | 32 | **成功运行** | **找到最终平衡点！** |

---

## 最终建议配置 (Final Recommended Configuration)

基于以上所有实验，我们为这块16GB显卡找到了**兼顾稳定与性能的最佳平衡点**：

*   `epochs`: 200
*   `batch_size`: **2**  *(我们能使用的、绝对安全的最高物理批次)*
*   `gradient_accumulation_steps`: **32** *(配合`batch_size`以模拟64的有效批次)*
*   `visnet_hidden_channels`: **80** *(在安全批次基础上，所能使用的最大模型宽度)*
*   `visnet_num_layers`: **4**
*   `visnet_num_rbf`: **80**
*   `max_atoms`: 10000

这套配置的核心思想是：**用绝对安全的最小物理批次，去承载我们能运行的、尽可能大的模型。** 它也许不是最快的，但它是在这块显卡上，能稳定跑完、并取得最好模型性能的唯一道路。
'''
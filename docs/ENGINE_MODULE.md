# 引擎模块 (`compass/engine`)

## 详细模块文档

*   [核心思想与工作流程](./CORE_IDEAS.md)
*   [数据模块 (`compass/data`)](./DATA_MODULE.md)
*   [模型模块 (`compass/training/model.py`)](./MODEL_MODULE.md)
*   [**引擎模块 (本文档)**](./ENGINE_MODULE.md)
*   [优化器模块 (`scripts/hardware_optimizer.py`)](./OPTIMIZER.md)

---

## 1. 核心解决的矛盾

想象一个场景：你已经准备好了[数据模块](./DATA_MODULE.md)和[模型模块](./MODEL_MODULE.md)，满怀期待地启动了训练脚本。一个复杂的模型可能需要运行数十个小时。这时，你可能会遇到几个令人沮丧的现实问题：

1.  **“哎呀！”时刻 (健壮性)**: 训练到第10个小时，服务器突然断电，或者你不小心按下了 `Ctrl+C`。如果没有一个健壮的引擎，你数天的计算成果将付诸东流。如何让训练过程像一个有“断点续传”功能的下载任务一样，能从上次中断的地方无缝恢复？

2.  **“GPU在偷懒”时刻 (效率)**: 你发现训练速度很慢，GPU利用率不高。你知道使用混合精度（`float16`）可以提速一倍，但它又会引入新的问题：`float16` 数值范围很小，微小的梯度很容易变成零（梯度下溢），导致模型不收敛。如何安全、高效地榨干硬件性能？

3.  **“意大利面条代码”时刻 (可维护性)**: 为了解决上述问题，你的训练循环里会塞满各种代码：检查点保存、信号处理、日志记录、混合精度、梯度裁剪…… 核心的 `前向->反向->优化` 逻辑被淹没在大量的模板代码中，难以阅读和维护。如何将高层逻辑与底层实现清晰地分离开？

本[引擎模块 (`compass/engine`)](./ENGINE_MODULE.md)的核心使命，就是解决上述所有矛盾，提供一个**健壮、高效、清晰**的训练“发动机”。

## 2. 工作流程与核心思想

本模块采用 **“指挥官-执行者” (Conductor-Executor)** 的设计模式，将复杂的训练流程拆分为两个层次：

-   **`Trainer` 类 (`trainer.py`) - 指挥官**: 负责顶层调度和状态管理，不关心每个批次的具体计算。
-   **`train/validate_epoch` 函数 (`loop.py`) - 执行者**: 负责单个 epoch 内的循环计算，专注于模型的核心逻辑。

### 指挥官 (`Trainer`) 的工作流程：

1.  **初始化**: 创建来自[模型模块](./MODEL_MODULE.md)的模型、优化器、学习率调度器 (`ReduceLROnPlateau`) 和用于混合精度训练的梯度缩放器 (`GradScaler`)。
2.  **加载状态 (Resume)**: 启动时，它会智能地在 `checkpoint_dir` 中查找最新的检查点。如果找到，它会恢复模型权重、优化器状态、当前 epoch 等所有信息。特别地，如果找到的是 `INTERRUPTED.pth.tar`，它会从上次中断的那个批次 (`batch_idx`) 开始，实现无缝续训。
3.  **设置“安全网” (Signal Handling)**: 它会注册系统信号处理器，能捕获用户的 `Ctrl+C` (SIGINT) 或系统关闭命令 (SIGTERM)。一旦捕获，它会立即触发一次紧急状态保存，确保用户的操作不会导致数据丢失。
4.  **驱动循环**: 进入主训练循环，按 epoch 调用 `train_epoch` 和 `validate_epoch` 函数，并根据 `validate_epoch` 的结果（验证集损失）来更新学习率调度器。
5.  **保存状态 (Checkpoint)**: 在每个 epoch 结束后，保存一次常规检查点 (`checkpoint.pth.tar`)。如果当前模型的验证性能超越了历史最佳，还会额外保存一份 `model_best.pth.tar`。

### 执行者 (`train_epoch`) 的核心算法思想：

`train_epoch` 函数内部是训练效率和稳定性的关键所在，它遵循以下步骤：

1.  **自动混合精度 (`autocast`)**: 整个前向传播过程被包裹在 `with autocast(...)` 上下文中。这使得兼容的 GPU 操作（如矩阵乘法）会自动使用半精度 `float16` 计算，极大提升速度并降低显存占用。
2.  **梯度缩放 (Gradient Scaling)**: 由于 `float16` 的数值范围较小，微小的梯度容易下溢变为零。因此，损失在反向传播前会由 `scaler` 乘以一个巨大的缩放因子，将梯度“放大”到一个安全的数值范围。
3.  **梯度累积 (Gradient Accumulation)**: `optimizer.step()` 不再是每个批次都执行，而是累积 `gradient_accumulation_steps` 个批次的梯度后才执行一次。这等效于使用了更大的批次进行训练，是一种在显存有限的情况下提升模型性能的常用技巧。
4.  **梯度反缩放与裁剪 (Unscaling & Clipping)**: 在执行优化前，`scaler` 会将梯度“反缩放”回其原始尺度。随后，通过 `clip_grad_norm_` 对梯度进行裁剪，防止因梯度爆炸导致的训练不稳定。

## 3. 常见问题与解决方案 (FAQ)

- **问：训练中途报错 `CUDA out of memory`，怎么办？**
  - **答：** 这是显存不足的典型错误。首选方案是在 `config.py` 中减小 `batch_size`。如果希望保持大的有效批量，可以相应地增大 `gradient_accumulation_steps` 的值来补偿。更好的方法是使用[优化器模块](./OPTIMIZER.md)来自动找到硬件支持的最佳 `batch_size`。

- **问：我不小心用 `Ctrl+C` 中断了训练，还能接着练吗？**
  - **答：** 完全可以。直接重新执行上次的训练命令即可。引擎的信号处理机制已经为您保存了中断时的状态，会自动从断点处恢复。

- **问：我想从头开始一次全新的训练，如何操作？**
  - **答：** 只需删除 `config.py` 中指定的 `checkpoint_dir` 目录，或将其指向一个新目录即可。引擎在启动时找不到任何检查点，就会自动从 `epoch 1` 开始。

- **问：训练日志里，验证集损失 (`Val Loss`) 很久不下降了，正常吗？**
  - **答：** 正常。请观察日志中的学习率 (`learning_rate`)。当 `Val Loss` 在 `patience`（例如3）个 epoch 内没有改善时，`ReduceLROnPlateau` 调度器会自动降低学习率。这是模型在尝试进入更精细的优化阶段。如果学习率已经很低且损失不再变化，说明模型可能已收敛。

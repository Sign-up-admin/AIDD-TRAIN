# 数据模块 (`compass/data`)

## 1. 核心解决的矛盾

在分子性质预测任务中，我们面临的核心矛盾是：**原始的、基于文本的分子结构文件（如 PDB、SDF）与深度学习模型（特别是图神经网络）所需的结构化、数值化的图数据格式之间存在巨大鸿沟。**

此模块的使命就是高效、可靠地跨越这一鸿沟。它不仅是简单的格式转换，更要解决以下具体挑战：
- **数据清洗与验证**: 原始数据可能包含错误、不一致或模型无法处理的超大分子。
- **特征工程**: 如何将化学概念（如原子类型、键类型）和物理概念（原子三维坐标）转化为有意义的、可供模型学习的数值特征。
- **效率**: PDBbind 等数据集包含数十万个分子，处理过程必须高效，能够利用多核 CPU 并行处理。
- **可复现性与缓存**: 数据处理是一个计算密集型操作。必须建立一套缓存机制，避免每次实验都重复处理；同时，当处理逻辑更新时，也能方便地强制重新生成数据。

## 2. 工作流程与核心思想

本模块的核心思想是 **“原始数据 -> 并行处理 -> 缓存化图数据”** 的流水线。

1.  **入口 (`dataset.py`)**: `PDBBindDataset` 类是整个数据流水线的总指挥。当它被实例化时，会检查 `processed_data` 目录下是否已经存在处理好的数据。
    - 如果存在且用户未强制要求重新处理 (`force_data_reprocessing: false`)，则直接加载缓存文件，极大提高了启动速度。
    - 如果不存在或用户要求强制刷新，它将启动 `process()` 方法。

2.  **并行调度 (`dataset.py`)**: `process()` 方法不会单打独斗，它会将每一个待处理的 PDB 条目打包成一个独立的“任务”，然后利用 Python 的 `multiprocessing.Pool` 将这些任务分发给多个 CPU核心并行执行。这使得数据处理速度能随 CPU 核心数近似线性提升。

3.  **原子化处理 (`processing.py`)**: `process_item` 函数是每个并行任务的核心执行单元，它负责对 **单个** PDB 条目进行精细化处理：
    - **加载与过滤**: 使用 RDKit 加载配体和蛋白质分子。同时进行“健康检查”，如文件大小、原子数量是否超出预设阈值 (`max_atoms`)，过滤掉异常数据。
    - **图的构建 (`graph/conversion.py`)**: 将配体和蛋白质的分子结构分别转换为图。这里的核心是 **避免原子位置重叠**：在处理蛋白质时，会排除掉那些已经属于配体的原子坐标，确保最终图的纯净性。
    - **特征生成 (`graph/features.py`)**: 为图中的每个原子（节点）生成特征向量。例如，将'C', 'O', 'N' 等元素符号转换为 one-hot 编码。
    - **数据组装**: 将配体图和蛋白质图合并为一个统一的 `torch_geometric.data.Data` 对象，并将结合亲和力数据 (`y`) 作为图的标签。
    - **最终校验**: 在返回之前，会进行最后一次检查，去除因浮点数精度问题可能导致的坐标完全相同的重复原子，确保数据质量。

4.  **输出**: `process_item` 处理完成的 `Data` 对象会被 `torch.save` 保存到 `processed_data` 目录下的对应位置，以 `.pt` 文件格式作为缓存。

## 3. 常见问题与解决方案 (FAQ)

- **问：数据处理非常缓慢，如何提速？**
  - **答：** 在 `config.py` 中，增大 `num_workers` 的值。建议设置为您机器 CPU 核心数或稍小的值，以最大化并行处理效率。

- **问：我修改了特征提取的逻辑（例如 `features.py`），但再次运行时模型用的还是旧数据？**
  - **答：** 这是因为缓存机制。为了让您的修改生效，请在 `config.py` 中设置 `force_data_reprocessing: true`。这会删除旧的 `processed_data` 目录，并强制重新生成所有数据。

- **问：日志中出现大量“Skipping PDB...”的警告，是什么原因？**
  - **答：** 请检查 `logs/processing.log` 文件获取详细原因。常见原因包括：
    1.  蛋白质文件过大或原子数过多（超过 `max_atoms` 配置）。
    2.  RDKit 无法解析分子结构，可能是原始 PDB 文件格式不标准。
    3.  配体文件（.sdf 或 .mol2）损坏或无法加载。

- **问：日志中出现“removed duplicate atom(s)”的警告，严重吗？**
  - **答：** 通常不严重。这是系统在合并配体和蛋白质时的一个最终安全检查，用于处理因坐标精度问题导致的微小重叠。只要不是所有数据都出现此警告，可以认为是正常现象。
